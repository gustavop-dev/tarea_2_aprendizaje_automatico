# ğŸ§  TAREA 2 - APRENDIZAJE AUTOMÃTICO

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa una **tarea completa de aprendizaje automÃ¡tico** que incluye:
- **Tarea Original**: Autoencoder con Gradient Accumulation  
- **Extra 1**: Vision Transformers para imÃ¡genes
- **Extra 2**: Algoritmos de clustering desde cero (K-means, DBSCAN, BFR)

Todas las implementaciones estÃ¡n desarrolladas **desde cero** usando conceptos fundamentales, con evaluaciones exhaustivas y documentaciÃ³n completa.

---

## ğŸ—ï¸ Estructura del Proyecto

```
ğŸ“¦ tarea_2_aprendizaje_automatico/
â”œâ”€â”€ ğŸ“ venv/                          # Entorno virtual Python
â”œâ”€â”€ ğŸ“ parte_1/                       # ğŸ¯ TAREA ORIGINAL
â”‚   â”œâ”€â”€ autoencoder.py                # Arquitectura Autoencoder en PyTorch
â”‚   â””â”€â”€ training.py                   # Training loop + Gradient Accumulation
â”œâ”€â”€ ğŸ“ parte_2/                       # â­ EXTRAS
â”‚   â”œâ”€â”€ vision_transformers_vs_cnn.py # ğŸ“– TeorÃ­a ViT vs CNNs
â”‚   â”œâ”€â”€ vision_autoencoder.py         # ğŸ—ï¸ ViT Autoencoder desde cero
â”‚   â”œâ”€â”€ vision_training.py            # ğŸš€ Training para imÃ¡genes (CIFAR-10)
â”‚   â”œâ”€â”€ clustering_algorithms.py      # ğŸ§® K-means, DBSCAN, BFR
â”‚   â”œâ”€â”€ clustering_evaluation.py      # ğŸ“Š EvaluaciÃ³n y comparaciÃ³n
â”‚   â””â”€â”€ README_parte2.md             # ğŸ“‹ DocumentaciÃ³n detallada
â”œâ”€â”€ ğŸ“„ requirements.txt               # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ .gitignore                     # Archivos a ignorar en Git
â””â”€â”€ ğŸ“„ README.md                      # ğŸ“‹ Este archivo
```

---

## ğŸ¯ **PARTE 1: TAREA ORIGINAL**

### ğŸ“ **Objetivos Cumplidos:**
âœ… **Construir arquitectura de red neuronal Autoencoder en PyTorch**  
âœ… **Escribir training loop con tÃ©cnica de Gradient Accumulation**

### ğŸ”§ **ImplementaciÃ³n:**

#### `autoencoder.py`
- **Clase `Autoencoder`** completa con encoder y decoder
- Arquitectura: `784 â†’ 128 â†’ 64 â†’ 32 â†’ 64 â†’ 128 â†’ 784`
- MÃ©todos `encode()`, `decode()` y `forward()`
- Activaciones ReLU y Sigmoid para normalizaciÃ³n

#### `training.py`  
- **Gradient Accumulation** implementado correctamente
- Dataset sintÃ©tico con patrones reconocibles
- Monitoreo de pÃ©rdidas por Ã©poca
- VisualizaciÃ³n de curvas de entrenamiento
- Guardado automÃ¡tico del modelo

### ğŸƒâ€â™‚ï¸ **CÃ³mo ejecutar:**
```bash
cd parte_1
python training.py
```

### ğŸ“Š **Resultados esperados:**
- Entrenamiento por 20 Ã©pocas
- Loss disminuye de ~0.33 â†’ ~0.25
- Modelo guardado como `autoencoder_model.pth`
- GrÃ¡fico de curva de entrenamiento

---

## â­ **PARTE 2: EXTRAS**

### ğŸ¯ **EXTRA 1: VISION TRANSFORMERS PARA IMÃGENES**

#### ğŸ“– **InvestigaciÃ³n y TeorÃ­a:**
- **Diferencias fundamentales** entre Vision Transformers y CNNs
- **AnÃ¡lisis comparativo** de arquitecturas, procesamiento y uso
- **Recomendaciones** de cuÃ¡ndo usar cada mÃ©todo

#### ğŸ—ï¸ **ImplementaciÃ³n desde cero:**
- **Vision Transformer Autoencoder** completo
- Componentes: Patch Embedding, Multi-Head Attention, Transformer Blocks
- **Training loop adaptado** para imÃ¡genes con CIFAR-10
- **Gradient Accumulation** implementado para ViT
- VisualizaciÃ³n de reconstrucciones de imÃ¡genes

#### ğŸƒâ€â™‚ï¸ **CÃ³mo ejecutar:**
```bash
cd parte_2

# Ver teorÃ­a ViT vs CNNs
python vision_transformers_vs_cnn.py

# Probar arquitectura ViT
python vision_autoencoder.py

# Entrenar con CIFAR-10 (recomendado)
python vision_training.py
```

#### ğŸ“Š **Resultados esperados:**
- Modelo con ~6.4M parÃ¡metros  
- Descarga automÃ¡tica de CIFAR-10
- Reconstrucciones visuales cada 5 Ã©pocas
- MÃ©tricas MSE, MAE, RMSE en test set

---

### ğŸ¯ **EXTRA 2: ALGORITMOS DE CLUSTERING**

#### ğŸ§® **Implementaciones desde cero:**

##### 1. **K-Means**
- InicializaciÃ³n aleatoria de centroides
- IteraciÃ³n hasta convergencia  
- CÃ¡lculo de inercia (WCSS)

##### 2. **DBSCAN**
- Algoritmo basado en densidad
- DetecciÃ³n automÃ¡tica de outliers
- Clusters de forma arbitraria

##### 3. **BFR (Bradley-Fayyad-Reina)**
- **Novedad**: Para datasets muy grandes
- Procesamiento en chunks (memoria limitada)
- Tres conjuntos: Discard, Compression, Retained

#### ğŸ“Š **EvaluaciÃ³n completa:**
- **Datasets**: Iris, Wine, Synthetic Blobs
- **MÃ©tricas**: ARI, Silhouette Score, NMI, V-measure
- **Visualizaciones** 2D de resultados
- **AnÃ¡lisis comparativo** detallado

#### ğŸƒâ€â™‚ï¸ **CÃ³mo ejecutar:**
```bash
cd parte_2

# Prueba bÃ¡sica de algoritmos
python clustering_algorithms.py

# EvaluaciÃ³n completa (RECOMENDADO)
python clustering_evaluation.py
```

#### ğŸ“Š **Resultados esperados:**
- ComparaciÃ³n de mÃ©tricas entre algoritmos
- GrÃ¡ficos de barras comparativos
- Visualizaciones 2D de clustering
- Recomendaciones de uso por algoritmo

---

## ğŸš€ **INSTRUCCIONES DE EJECUCIÃ“N COMPLETAS**

### 1ï¸âƒ£ **ConfiguraciÃ³n inicial:**
```bash
# Clonar o descargar el proyecto
cd tarea_2_aprendizaje_automatico

# Crear y activar entorno virtual (ya creado)
source venv/bin/activate

# Verificar dependencias (ya instaladas)
pip list
```

### 2ï¸âƒ£ **Ejecutar Parte 1 (Tarea Original):**
```bash
# Autoencoder bÃ¡sico con Gradient Accumulation
cd parte_1
python training.py
cd ..
```

### 3ï¸âƒ£ **Ejecutar Parte 2 - Extra 1 (Vision Transformers):**
```bash
cd parte_2

# TeorÃ­a y comparaciÃ³n ViT vs CNNs
python vision_transformers_vs_cnn.py

# Probar arquitectura ViT
python vision_autoencoder.py

# Entrenar con imÃ¡genes reales (CIFAR-10)
python vision_training.py
```

### 4ï¸âƒ£ **Ejecutar Parte 2 - Extra 2 (Clustering):**
```bash
# Desde parte_2/

# Algoritmos bÃ¡sicos
python clustering_algorithms.py

# EvaluaciÃ³n completa con mÃ©tricas
python clustering_evaluation.py
```

---

## ğŸ“¦ **Dependencias**

```txt
torch>=2.0.0           # PyTorch para redes neuronales
torchvision>=0.15.0    # Datasets e imÃ¡genes  
numpy>=1.20.0          # ComputaciÃ³n numÃ©rica
matplotlib>=3.5.0      # Visualizaciones
scikit-learn>=1.0.0    # MÃ©tricas de evaluaciÃ³n
pandas>=1.3.0          # ManipulaciÃ³n de datos
```

InstalaciÃ³n automÃ¡tica:
```bash
pip install -r requirements.txt
```

---

## ğŸ† **CaracterÃ­sticas Destacadas**

### âœ¨ **Implementaciones desde cero:**
- No uso librerÃ­as pre-existentes para algoritmos principales
- Conceptos fundamentales implementados manualmente
- CÃ³digo educativo y bien documentado

### âœ¨ **Gradient Accumulation:**
- Implementado en **ambas partes** del proyecto
- TÃ©cnica para simular batches mÃ¡s grandes
- OptimizaciÃ³n de memoria y estabilidad

### âœ¨ **EvaluaciÃ³n exhaustiva:**
- **MÃºltiples mÃ©tricas** de evaluaciÃ³n
- **Datasets reales** (CIFAR-10, Iris, Wine)
- **Visualizaciones** y grÃ¡ficos comparativos

### âœ¨ **DocumentaciÃ³n completa:**
- READMEs detallados en cada parte
- Explicaciones teÃ³ricas incluidas  
- Instrucciones paso a paso

---

## ğŸ¯ **Respuestas a Preguntas Clave**

### **"Â¿QuÃ© mÃ©trica usarÃ­a para clustering?"**
**Adjusted Rand Index (ARI)** como mÃ©trica principal:
- EvalÃºa similitud con estructura real de datos
- Corrige asignaciones casuales  
- Rango intuitivo [-1, 1] donde 1 = perfecto
- Ideal para comparar algoritmos diferentes

### **"Diferencias ViT vs CNNs?"**
| Aspecto | CNNs | Vision Transformers |
|---------|------|-------------------|
| **Arquitectura** | Convoluciones | Self-Attention |
| **Campo Receptivo** | Local â†’ Global | Global desde inicio |
| **Datos Necesarios** | Pocos | Muchos |
| **Eficiencia** | Alta | Media |

---

## ğŸ’¡ **Resultados y Conclusiones**

### **Autoencoder (Parte 1):**
- âœ… Convergencia exitosa en ~20 Ã©pocas
- âœ… Loss: 0.33 â†’ 0.25
- âœ… Gradient Accumulation funcional

### **Vision Transformers (Extra 1):**
- âœ… Modelo funcional con 6.4M parÃ¡metros
- âœ… Reconstrucciones visuales de CIFAR-10
- âœ… Training estable con ViT

### **Clustering (Extra 2):**
- âœ… K-Means: Mejor para clusters esfÃ©ricos
- âœ… DBSCAN: Mejor para formas irregulares  
- âœ… BFR: Mejor para datasets grandes
- âœ… ARI como mÃ©trica recomendada

---