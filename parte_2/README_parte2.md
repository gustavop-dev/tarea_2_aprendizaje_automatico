# PARTE 2 - EXTRAS DE APRENDIZAJE AUTOMÃTICO

## ğŸ“‹ Contenido Implementado

Esta carpeta contiene la implementaciÃ³n de **dos extras** solicitados por el profesor:

### ğŸ¯ **EXTRA 1: Vision Transformers para ImÃ¡genes**
- **Objetivo**: Adaptar autoencoder para funcionar con imÃ¡genes usando Vision Transformers
- **InvestigaciÃ³n**: Diferencias entre Vision Transformers y CNNs
- **ImplementaciÃ³n**: Autoencoder basado en ViT con gradient accumulation

### ğŸ¯ **EXTRA 2: Algoritmos de Clustering**
- **Objetivo**: Implementar K-means, DBSCAN y BFR desde cero
- **ComparaciÃ³n**: Evaluar los tres mÃ©todos con mÃºltiples mÃ©tricas
- **Dataset**: Datasets tabulares (Iris, Wine, sintÃ©ticos)

---

## ğŸ“ Estructura de Archivos

```
parte_2/
â”œâ”€â”€ vision_transformers_vs_cnn.py    # ğŸ“– TeorÃ­a: ViT vs CNNs
â”œâ”€â”€ vision_autoencoder.py            # ğŸ—ï¸ ImplementaciÃ³n ViT Autoencoder  
â”œâ”€â”€ vision_training.py               # ğŸš€ Training loop para imÃ¡genes
â”œâ”€â”€ clustering_algorithms.py         # ğŸ§® K-means, DBSCAN, BFR desde cero
â”œâ”€â”€ clustering_evaluation.py         # ğŸ“Š EvaluaciÃ³n y comparaciÃ³n completa
â””â”€â”€ README_parte2.md                # ğŸ“‹ Este archivo
```

---

## ğŸ” **EXTRA 1: VISION TRANSFORMERS**

### **Archivos principales:**
- `vision_transformers_vs_cnn.py`: ExplicaciÃ³n teÃ³rica completa
- `vision_autoencoder.py`: ImplementaciÃ³n desde cero del Vision Transformer Autoencoder
- `vision_training.py`: Training loop adaptado para imÃ¡genes con CIFAR-10

### **CaracterÃ­sticas implementadas:**
âœ… **Vision Transformer completo** con:
- Patch Embedding
- Multi-Head Self-Attention
- Transformer Blocks
- Positional Encoding

âœ… **Autoencoder Architecture**:
- Encoder basado en ViT
- Decoder para reconstrucciÃ³n de imÃ¡genes
- Espacio latente configurable

âœ… **Training adaptado**:
- Gradient Accumulation implementado
- Dataset CIFAR-10 automÃ¡tico
- VisualizaciÃ³n de reconstrucciones
- MÃ©tricas de evaluaciÃ³n (MSE, MAE)

### **Principales diferencias ViT vs CNN:**

| Aspecto | CNNs | Vision Transformers |
|---------|------|-------------------|
| **Arquitectura** | Convoluciones + Pooling | Self-Attention + MLP |
| **Inductive Bias** | Localidad espacial | Ninguno (aprende relaciones) |
| **Campo Receptivo** | Limitado inicialmente | Global desde el inicio |
| **Datos Requeridos** | Funcionan con pocos datos | Requieren datasets grandes |
| **Eficiencia** | Muy eficientes | MÃ¡s costosos computacionalmente |

### **CuÃ¡ndo usar cada uno:**
- **CNNs**: Datasets pequeÃ±os, recursos limitados, necesitas interpretabilidad
- **ViTs**: Datasets grandes, recursos abundantes, relaciones globales importantes

---

## ğŸ” **EXTRA 2: ALGORITMOS DE CLUSTERING**

### **Archivos principales:**
- `clustering_algorithms.py`: Implementaciones desde cero
- `clustering_evaluation.py`: EvaluaciÃ³n completa con mÃ©tricas

### **Algoritmos implementados:**

#### ğŸ¯ **1. K-Means (desde cero)**
- InicializaciÃ³n aleatoria de centroides
- IteraciÃ³n hasta convergencia
- CÃ¡lculo de inercia (WCSS)
- Optimizado y eficiente

#### ğŸ¯ **2. DBSCAN (desde cero)**
- Algoritmo basado en densidad
- DetecciÃ³n automÃ¡tica de outliers
- No requiere especificar nÃºmero de clusters
- Manejo de clusters de forma irregular

#### ğŸ¯ **3. BFR - Bradley-Fayyad-Reina (desde cero)**
- **Novedad**: Algoritmo para datasets muy grandes
- Procesamiento en chunks (memoria limitada)
- Mantiene estadÃ­sticas resumidas (N, SUM, SUMSQ)
- Tres conjuntos: Discard Set, Compression Set, Retained Set
- Ideal para streaming de datos

### **MÃ©tricas de evaluaciÃ³n utilizadas:**

| MÃ©trica | Rango | DescripciÃ³n | CuÃ¡ndo usar |
|---------|-------|-------------|-------------|
| **Adjusted Rand Index (ARI)** | [-1, 1] | Similitud con etiquetas verdaderas | Con ground truth |
| **Silhouette Score** | [-1, 1] | CohesiÃ³n vs separaciÃ³n | Sin ground truth |
| **Normalized Mutual Info** | [0, 1] | InformaciÃ³n mutua normalizada | Con ground truth |
| **V-measure** | [0, 1] | Combina homogeneidad y completeness | Con ground truth |

### **Datasets evaluados:**
- **Synthetic Blobs**: Dataset sintÃ©tico 2D para visualizaciÃ³n
- **Iris**: Dataset clÃ¡sico de flores (4 caracterÃ­sticas, 3 clases)
- **Wine**: Dataset de vinos (13 caracterÃ­sticas, 3 clases)

### **Recomendaciones de uso:**

#### ğŸ”§ **K-Means**
âœ… **Usar cuando:**
- Clusters esfÃ©ricos y bien separados
- Dataset sin muchos outliers
- Necesitas eficiencia computacional

#### ğŸ”§ **DBSCAN**
âœ… **Usar cuando:**
- Clusters de forma irregular
- Presencia de outliers/ruido
- No sabes cuÃ¡ntos clusters hay

#### ğŸ”§ **BFR**
âœ… **Usar cuando:**
- Datasets extremadamente grandes
- Memoria limitada
- Datos llegando en streaming

---

## ğŸ† **MÃ‰TRICA RECOMENDADA**

### **Para tu tarea especÃ­fica:**
**Adjusted Rand Index (ARI)** es la mÃ©trica principal recomendada porque:
- EvalÃºa quÃ© tan bien los algoritmos descubren la estructura real
- Corrige por asignaciones casuales
- Funciona bien para comparar diferentes algoritmos
- Rango intuitivo [-1, 1] donde 1 = perfecto

### **MÃ©trica secundaria:**
**Silhouette Score** como mÃ©trica intrÃ­nseca (no requiere etiquetas verdaderas)

---

## ğŸš€ **CÃ³mo ejecutar:**

### **Extra 1 - Vision Transformers:**
```bash
cd parte_2

# Ver explicaciÃ³n teÃ³rica
python vision_transformers_vs_cnn.py

# Probar arquitectura
python vision_autoencoder.py

# Entrenar con CIFAR-10 (toma unos minutos)
python vision_training.py
```

### **Extra 2 - Clustering:**
```bash
cd parte_2

# Probar algoritmos bÃ¡sicos
python clustering_algorithms.py

# EvaluaciÃ³n completa (recomendado)
python clustering_evaluation.py
```

---

## ğŸ“Š **Resultados esperados:**

### **Vision Transformers:**
- Modelo con ~6.4M parÃ¡metros
- Reconstrucciones de imÃ¡genes CIFAR-10
- Curvas de entrenamiento
- ComparaciÃ³n visual original vs reconstruido

### **Clustering:**
- ComparaciÃ³n de mÃ©tricas entre algoritmos
- Visualizaciones 2D de resultados
- AnÃ¡lisis de fortalezas/debilidades
- Recomendaciones de uso

---

## âœ¨ **CaracterÃ­sticas destacadas:**

1. **Implementaciones desde cero** - No usar librerÃ­as, solo conceptos fundamentales
2. **Gradient Accumulation** - Implementado en ambos extras
3. **EvaluaciÃ³n exhaustiva** - MÃºltiples mÃ©tricas y datasets
4. **Visualizaciones** - GrÃ¡ficos y comparaciones visuales
5. **DocumentaciÃ³n completa** - Explicaciones teÃ³ricas y prÃ¡cticas

---

Â¡Tarea completada con Ã©xito! ğŸ‰ 